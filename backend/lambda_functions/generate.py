import json
import boto3
import traceback
import time
from datetime import datetime
from typing import Dict, Any, Optional

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
bedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')
dynamodb = boto3.resource('dynamodb', region_name='us-east-1')

# ëª¨ë¸ ì„¤ì •
MODEL_ID = "anthropic.claude-3-sonnet-20240229-v1:0"

def lambda_handler(event, context):
    """
    AWS Lambda í•¸ë“¤ëŸ¬: ì œëª© ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    """
    try:
        print(f"ğŸ“¨ ìš”ì²­ ìˆ˜ì‹ : {json.dumps(event, ensure_ascii=False, default=str)}")
        
        # HTTP ë©”ì„œë“œ í™•ì¸
        http_method = event.get('httpMethod', 'POST')
        path = event.get('path', '')
        
        # ê²½ë¡œì—ì„œ í”„ë¡œì íŠ¸ ID ì¶”ì¶œ
        path_parts = path.strip('/').split('/')
        project_id = None
        
        for i, part in enumerate(path_parts):
            if part == 'projects' and i + 1 < len(path_parts):
                project_id = path_parts[i + 1]
                break
        
        if not project_id:
            return create_error_response(400, "í”„ë¡œì íŠ¸ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ğŸ”§ GET ìš”ì²­ ì²˜ë¦¬ (SSEìš©)
        if http_method == 'GET':
            query_params = event.get('queryStringParameters') or {}
            
            body = {
                'userInput': query_params.get('userInput', ''),
                'chat_history': json.loads(query_params.get('chat_history', '[]')),
            }
            
            # ì…ë ¥ ê²€ì¦
            if not body.get('userInput', '').strip():
                return create_sse_error_response("ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤")
                
        # ğŸ”§ POST ìš”ì²­ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        else:
            # POST ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
            if isinstance(event.get('body'), str):
                body = json.loads(event['body'])
            else:
                body = event.get('body', {})
            
            # ì…ë ¥ ê²€ì¦
            if not body.get('userInput', '').strip():
                return create_error_response(400, "ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì²˜ë¦¬
        if '/stream' in path:
            return handle_streaming_generation(project_id, body, context, http_method)
        else:
            return handle_standard_generation(project_id, body, context)
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return create_error_response(400, "ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return create_error_response(500, "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

def handle_streaming_generation(project_id, body, context, http_method='POST'):
    """
    ğŸ”§ ê°œì„ ëœ ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì²˜ë¦¬ - SSE ì§€ì›
    """
    try:
        user_input = body.get('userInput', '')
        chat_history = body.get('chat_history', [])
        
        print(f"ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì‹œì‘: {project_id}, ì…ë ¥ ê¸¸ì´: {len(user_input)}, ë©”ì„œë“œ: {http_method}")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        final_prompt = build_final_prompt(project_id, user_input, chat_history)
        
        # ğŸ”§ SSE ì‘ë‹µ í—¤ë” ì„¤ì •
        headers = {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache, no-store, must-revalidate',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type, Cache-Control, Connection',
            'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
            'Access-Control-Expose-Headers': 'Content-Type, Cache-Control, Connection',
        }
        
        # Bedrock ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        start_time = time.time()
        response = bedrock_client.invoke_model_with_response_stream(
            modelId=MODEL_ID,
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 4000,
                "messages": [{"role": "user", "content": final_prompt}],
                "temperature": 0.7,
                "top_p": 0.9,
            }),
            contentType="application/json",
            accept="application/json"
        )
        
        # ğŸ”§ SSE í˜•íƒœë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        streaming_chunks = []
        full_response = ""
        chunk_count = 0
        
        for event in response['body']:
            if 'chunk' in event:
                chunk_data = json.loads(event['chunk']['bytes'].decode('utf-8'))
                
                if chunk_data.get('type') == 'content_block_delta':
                    if 'delta' in chunk_data and 'text' in chunk_data['delta']:
                        chunk_text = chunk_data['delta']['text']
                        full_response += chunk_text
                        chunk_count += 1
                        
                        # ğŸ”§ SSE í˜•íƒœë¡œ ì²­í¬ ë°ì´í„° í¬ë§·íŒ…
                        sse_data = {
                            'response': chunk_text,
                            'sessionId': project_id,
                            'timestamp': datetime.now().isoformat(),
                            'type': 'chunk',
                            'chunkNumber': chunk_count
                        }
                        
                        streaming_chunks.append(f"data: {json.dumps(sse_data, ensure_ascii=False)}\n\n")
        
        # ğŸ”§ ì™„ë£Œ ì´ë²¤íŠ¸ ì¶”ê°€
        end_time = time.time()
        processing_time = round(end_time - start_time, 2)
        
        completion_data = {
            'response': '',
            'sessionId': project_id,
            'timestamp': datetime.now().isoformat(),
            'type': 'complete',
            'fullResponse': full_response,
            'processingTime': processing_time,
            'totalChunks': chunk_count,
            'responseLength': len(full_response)
        }
        streaming_chunks.append(f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n")
        
        print(f"âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {processing_time}ì´ˆ, {chunk_count}ê°œ ì²­í¬, {len(full_response)}ì")
        
        # ğŸ”§ SSE ì‘ë‹µ ë°˜í™˜
        return {
            'statusCode': 200,
            'headers': headers,
            'body': ''.join(streaming_chunks),
            'isBase64Encoded': False
        }
        
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        headers = {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Access-Control-Allow-Origin': '*',
        }
        
        error_data = {
            'error': str(e),
            'sessionId': project_id,
            'timestamp': datetime.now().isoformat(),
            'type': 'error'
        }
        
        return {
            'statusCode': 500,
            'headers': headers,
            'body': f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        }

def handle_standard_generation(project_id, body, context):
    """
    ì¼ë°˜ ì œëª© ìƒì„± ì²˜ë¦¬ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
    """
    try:
        user_input = body.get('userInput', '')
        chat_history = body.get('chat_history', [])
        
        print(f"ğŸ“ ì¼ë°˜ ìƒì„± ì‹œì‘: {project_id}, ì…ë ¥ ê¸¸ì´: {len(user_input)}")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        final_prompt = build_final_prompt(project_id, user_input, chat_history)
        
        # Bedrock í˜¸ì¶œ
        start_time = time.time()
        response = bedrock_client.invoke_model(
            modelId=MODEL_ID,
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 4000,
                "messages": [{"role": "user", "content": final_prompt}],
                "temperature": 0.7,
                "top_p": 0.9,
            }),
            contentType="application/json",
            accept="application/json"
        )
        
        # ì‘ë‹µ íŒŒì‹±
        response_body = json.loads(response['body'].read())
        generated_text = response_body['content'][0]['text']
        
        end_time = time.time()
        processing_time = round(end_time - start_time, 2)
        
        print(f"âœ… ì¼ë°˜ ìƒì„± ì™„ë£Œ: {processing_time}ì´ˆ, {len(generated_text)}ì")
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
            },
            'body': json.dumps({
                'result': generated_text,
                'mode': 'standard',
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat(),
                'message': 'ì œëª© ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        print(f"âŒ ì¼ë°˜ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return create_error_response(500, f"ì œëª© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def build_final_prompt(project_id: str, user_input: str, chat_history: list) -> str:
    """
    í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    """
    try:
        # í”„ë¡¬í”„íŠ¸ ì¹´ë“œ ë¡œë“œ
        prompt_cards = load_prompt_cards(project_id)
        
        if not prompt_cards:
            return f"ì‚¬ìš©ì ìš”ì²­: {user_input}"
        
        # í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¥¼ stepOrder ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_cards = sorted(prompt_cards, key=lambda x: x.get('stepOrder', 999))
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_parts = []
        for card in sorted_cards:
            if card.get('isActive', True) and card.get('content'):
                system_parts.append(f"[{card.get('title', 'ë‹¨ê³„')}]\n{card['content']}")
        
        system_prompt = "\n\n".join(system_parts) if system_parts else "ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í¬í•¨
        context_parts = [system_prompt]
        
        if chat_history:
            context_parts.append("\n[ì´ì „ ëŒ€í™” ë‚´ìš©]")
            for msg in chat_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ í¬í•¨
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                if content.strip():
                    context_parts.append(f"{role}: {content}")
        
        context_parts.append(f"\n[í˜„ì¬ ìš”ì²­]\nì‚¬ìš©ì: {user_input}")
        context_parts.append("\nì–´ì‹œìŠ¤í„´íŠ¸:")
        
        return "\n".join(context_parts)
        
    except Exception as e:
        print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì˜¤ë¥˜: {str(e)}")
        return f"ì‚¬ìš©ì ìš”ì²­: {user_input}"

def load_prompt_cards(project_id: str) -> list:
    """
    í”„ë¡œì íŠ¸ì˜ í”„ë¡¬í”„íŠ¸ ì¹´ë“œ ë¡œë“œ
    """
    try:
        table = dynamodb.Table('BedrockDiyPrompts')
        
        response = table.query(
            KeyConditionExpression=boto3.dynamodb.conditions.Key('projectId').eq(project_id),
            ProjectionExpression='promptId, title, content, stepOrder, isActive'
        )
        
        return response.get('Items', [])
        
    except Exception as e:
        print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ì¹´ë“œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return []

def create_error_response(status_code: int, message: str) -> Dict[str, Any]:
    """í‘œì¤€ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
    return {
        'statusCode': status_code,
        'headers': {
            'Content-Type': 'application/json',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type',
            'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
        },
        'body': json.dumps({
            'error': message,
            'timestamp': datetime.now().isoformat()
        }, ensure_ascii=False)
    }

def create_sse_error_response(error_message: str) -> Dict[str, Any]:
    """SSE í˜•íƒœì˜ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
    headers = {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Headers': 'Content-Type',
        'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
    }
    
    error_data = {
        'error': error_message,
        'timestamp': datetime.now().isoformat(),
        'type': 'error'
    }
    
    return {
        'statusCode': 400,
        'headers': headers,
        'body': f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    } 