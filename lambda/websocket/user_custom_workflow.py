"""
ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì¹´ë“œ ê¸°ë°˜ ë™ì  LangGraph ì›Œí¬í”Œë¡œìš°
"""
from typing import TypedDict, List, Dict, Any, Optional
import json
import os
import boto3

# LangGraph ì˜ì¡´ì„±ì„ ì„ íƒì ìœ¼ë¡œ import
try:
    from langgraph.graph import StateGraph, END
    from langchain_aws import ChatBedrock
    LANGGRAPH_DEPS_AVAILABLE = True
except ImportError as e:
    print(f"LangGraph ì˜ì¡´ì„± ì—†ìŒ: {e}")
    LANGGRAPH_DEPS_AVAILABLE = False
    
    # ë”ë¯¸ í´ë˜ìŠ¤ë“¤ë¡œ ëŒ€ì²´
    class StateGraph:
        def __init__(self, state_type): pass
        def add_node(self, name, func): pass
        def add_edge(self, from_node, to_node): pass
        def add_conditional_edges(self, node, condition, mapping): pass
        def set_entry_point(self, node): pass
        def compile(self): return self
        def invoke(self, state): return state
    
    END = "END"

class CustomWorkflowState(TypedDict):
    """ì‚¬ìš©ì ë§ì¶¤ ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    user_input: str
    user_prompt_cards: List[Dict[str, Any]]  # ì‚¬ìš©ìê°€ ë§Œë“  í”„ë¡¬í”„íŠ¸ ì¹´ë“œë“¤
    current_step: int
    step_results: List[Dict[str, Any]]
    accumulated_context: str
    final_answer: str
    websocket_connection: str

def create_dynamic_workflow_from_cards(prompt_cards: List[Dict[str, Any]]):
    """
    ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì›Œí¬í”Œë¡œìš° ìƒì„±
    
    Args:
        prompt_cards: [
            {
                "promptId": "card1",
                "title": "ë¬¸ì œ ë¶„ì„",
                "prompt_text": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.",
                "stepOrder": 1
            },
            {
                "promptId": "card2", 
                "title": "ì†”ë£¨ì…˜ íƒìƒ‰",
                "prompt_text": "ë¶„ì„ëœ ë¬¸ì œì— ëŒ€í•œ 3ê°€ì§€ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.",
                "stepOrder": 2
            },
            ...
        ]
    """
    
    # í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¥¼ stepOrderë¡œ ì •ë ¬
    sorted_cards = sorted(prompt_cards, key=lambda x: x.get('stepOrder', 0))
    
    workflow = StateGraph(CustomWorkflowState)
    
    # ì‹œì‘ ë…¸ë“œ
    workflow.add_node("initialize", initialize_workflow)
    
    # ê° í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¥¼ ê°œë³„ ë…¸ë“œë¡œ ìƒì„±
    previous_node = "initialize"
    
    for i, card in enumerate(sorted_cards):
        node_name = f"step_{i+1}_{card['promptId']}"
        
        # ë™ì ìœ¼ë¡œ ì‹¤í–‰ í•¨ìˆ˜ ìƒì„±
        def create_step_function(card_data):
            def execute_step(state: CustomWorkflowState) -> CustomWorkflowState:
                return execute_prompt_card_step(state, card_data)
            return execute_step
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node(node_name, create_step_function(card))
        
        # ì´ì „ ë…¸ë“œì™€ ì—°ê²°
        workflow.add_edge(previous_node, node_name)
        previous_node = node_name
    
    # ìµœì¢… ì •ë¦¬ ë…¸ë“œ
    workflow.add_node("finalize", finalize_custom_workflow)
    workflow.add_edge(previous_node, "finalize")
    workflow.add_edge("finalize", END)
    
    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("initialize")
    
    return workflow.compile()

def initialize_workflow(state: CustomWorkflowState) -> CustomWorkflowState:
    """ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”"""
    connection_id = state["websocket_connection"]
    
    send_thinking_step(connection_id, {
        "type": "workflow_start",
        "title": "ğŸš€ ë§ì¶¤í˜• ì‚¬ê³ ê³¼ì • ì‹œì‘",
        "message": f"{len(state['user_prompt_cards'])}ë‹¨ê³„ì˜ ì‚¬ê³ ê³¼ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
        "total_steps": len(state["user_prompt_cards"])
    })
    
    state["current_step"] = 0
    state["step_results"] = []
    state["accumulated_context"] = ""
    
    return state

def execute_prompt_card_step(state: CustomWorkflowState, card: Dict[str, Any]) -> CustomWorkflowState:
    """ê°œë³„ í”„ë¡¬í”„íŠ¸ ì¹´ë“œ ì‹¤í–‰"""
    connection_id = state["websocket_connection"]
    step_number = state["current_step"] + 1
    
    card_title = card.get("title", f"ë‹¨ê³„ {step_number}")
    card_prompt = card.get("prompt_text", "")
    
    # ì‚¬ê³ ê³¼ì • ì‹œì‘ ì•Œë¦¼
    send_thinking_step(connection_id, {
        "type": "step_start",
        "step_number": step_number,
        "title": f"ğŸ§  {card_title}",
        "instruction": card_prompt,
        "status": "processing"
    })
    
    # í˜„ì¬ê¹Œì§€ì˜ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    full_prompt = build_contextual_prompt(
        user_input=state["user_input"],
        card_instruction=card_prompt,
        previous_context=state["accumulated_context"]
    )
    
    # Claude API í˜¸ì¶œ
    llm = ChatBedrock(
        model_id="apac.anthropic.claude-sonnet-4-20250514-v1:0",
        model_kwargs={"temperature": 0.3, "max_tokens": 65536}
    )
    
    try:
        response = llm.invoke([
            {"role": "user", "content": full_prompt}
        ])
        
        step_result = response.content
        
        # ê²°ê³¼ ì €ì¥
        state["step_results"].append({
            "step": step_number,
            "card_id": card.get("promptId"),
            "title": card_title,
            "instruction": card_prompt,
            "result": step_result,
            "timestamp": "now"
        })
        
        # ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        state["accumulated_context"] += f"\n\n## {card_title}\n{step_result}"
        state["current_step"] = step_number
        
        # ë‹¨ê³„ ì™„ë£Œ ì•Œë¦¼
        send_thinking_step(connection_id, {
            "type": "step_complete",
            "step_number": step_number,
            "title": f"âœ… {card_title} ì™„ë£Œ",
            "result": step_result[:200] + "..." if len(step_result) > 200 else step_result,
            "full_result": step_result,
            "status": "completed"
        })
        
    except Exception as e:
        # ì˜¤ë¥˜ ì²˜ë¦¬
        error_msg = f"ë‹¨ê³„ {step_number} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        
        state["step_results"].append({
            "step": step_number,
            "card_id": card.get("promptId"),
            "title": card_title,
            "error": error_msg,
            "timestamp": "now"
        })
        
        send_thinking_step(connection_id, {
            "type": "step_error",
            "step_number": step_number,
            "title": f"âŒ {card_title} ì˜¤ë¥˜",
            "error": error_msg,
            "status": "error"
        })
    
    return state

def finalize_custom_workflow(state: CustomWorkflowState) -> CustomWorkflowState:
    """ë§ì¶¤í˜• ì›Œí¬í”Œë¡œìš° ìµœì¢… ì •ë¦¬"""
    connection_id = state["websocket_connection"]
    
    # ìµœì¢… ë‹µë³€ ìƒì„±
    send_thinking_step(connection_id, {
        "type": "final_synthesis",
        "title": "ğŸ¯ ìµœì¢… ë‹µë³€ ìƒì„±",
        "message": "ëª¨ë“  ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        "status": "processing"
    })
    
    # ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸
    synthesis_prompt = f"""
    ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¨ê³„ë³„ë¡œ ì‚¬ê³ í•œ ê²°ê³¼ì…ë‹ˆë‹¤:

    **ì›ë³¸ ì§ˆë¬¸**: {state["user_input"]}

    **ë‹¨ê³„ë³„ ì‚¬ê³ ê³¼ì •**:
    {state["accumulated_context"]}

    ìœ„ì˜ ëª¨ë“  ë‹¨ê³„ë³„ ì‚¬ê³ ê³¼ì •ì„ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•˜ê³  ì™„ì„±ë„ ë†’ì€ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    
    llm = ChatBedrock(
        model_id="apac.anthropic.claude-sonnet-4-20250514-v1:0",
        model_kwargs={"temperature": 0.2, "max_tokens": 65536}
    )
    
    try:
        final_response = llm.invoke([
            {"role": "user", "content": synthesis_prompt}
        ])
        
        state["final_answer"] = final_response.content
        
        # ìµœì¢… ë‹µë³€ ì™„ë£Œ ì•Œë¦¼
        send_thinking_step(connection_id, {
            "type": "workflow_complete",
            "title": "ğŸ‰ ì‚¬ê³ ê³¼ì • ì™„ë£Œ",
            "message": "ëª¨ë“  ë‹¨ê³„ì˜ ì‚¬ê³ ê³¼ì •ì„ ê±°ì³ ìµœì¢… ë‹µë³€ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "summary": {
                "total_steps": len(state["step_results"]),
                "successful_steps": len([r for r in state["step_results"] if "error" not in r]),
                "final_answer": state["final_answer"]
            },
            "status": "completed"
        })
        
    except Exception as e:
        # ìµœì¢… ë‹¨ê³„ ì˜¤ë¥˜ì‹œ ì´ì „ ê²°ê³¼ë“¤ì„ ì¡°í•©
        state["final_answer"] = state["accumulated_context"]
        
        send_thinking_step(connection_id, {
            "type": "workflow_error",
            "title": "âš ï¸ ìµœì¢… ì •ë¦¬ ì¤‘ ì˜¤ë¥˜",
            "message": "ìµœì¢… ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ, ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "error": str(e)
        })
    
    return state

def build_contextual_prompt(user_input: str, card_instruction: str, previous_context: str) -> str:
    """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    
    prompt_parts = []
    
    # 1. ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸
    prompt_parts.append(f"**ì‚¬ìš©ì ì§ˆë¬¸**: {user_input}")
    
    # 2. ì´ì „ ë‹¨ê³„ ê²°ê³¼ (ìˆëŠ” ê²½ìš°)
    if previous_context.strip():
        prompt_parts.append(f"**ì´ì „ ë‹¨ê³„ ê²°ê³¼**:\n{previous_context}")
    
    # 3. í˜„ì¬ ë‹¨ê³„ ì§€ì‹œì‚¬í•­
    prompt_parts.append(f"**í˜„ì¬ ë‹¨ê³„ ì§€ì‹œì‚¬í•­**:\n{card_instruction}")
    
    # 4. ì‹¤í–‰ ì§€ì¹¨
    prompt_parts.append("""
**ì‹¤í–‰ ì§€ì¹¨**:
- ìœ„ì˜ ì§€ì‹œì‚¬í•­ì„ ì •í™•íˆ ë”°ë¼ ì‹¤í–‰í•˜ì„¸ìš”
- ì´ì „ ë‹¨ê³„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
""")
    
    return "\n\n".join(prompt_parts)

def send_thinking_step(connection_id: str, step_data: Dict):
    """WebSocketìœ¼ë¡œ ì‚¬ê³ ê³¼ì • ì „ì†¡"""
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” apigateway_client ì‚¬ìš©
    print(f"WebSocket [{connection_id}]: {step_data}")
    
    # ì‹¤ì œ WebSocket ì „ì†¡ ë¡œì§
    try:
        import boto3
        apigateway_client = boto3.client('apigatewaymanagementapi', 
                                       endpoint_url=f"https://{os.environ.get('DOMAIN_NAME')}/{os.environ.get('STAGE')}")
        
        apigateway_client.post_to_connection(
            ConnectionId=connection_id,
            Data=json.dumps(step_data)
        )
    except Exception as e:
        print(f"WebSocket ì „ì†¡ ì‹¤íŒ¨: {e}")

# ì‚¬ìš© ì˜ˆì‹œ
def create_user_workflow(user_prompt_cards: List[Dict[str, Any]]):
    """
    ì‚¬ìš©ìê°€ ë§Œë“  í”„ë¡¬í”„íŠ¸ ì¹´ë“œë¡œ ì›Œí¬í”Œë¡œìš° ìƒì„±
    
    ì˜ˆì‹œ ì‚¬ìš©:
    user_cards = [
        {
            "promptId": "analysis_card",
            "title": "ë¬¸ì œ ë¶„ì„", 
            "prompt_text": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•µì‹¬ ìš”ì†Œ 3ê°€ì§€ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.",
            "stepOrder": 1
        },
        {
            "promptId": "solution_card",
            "title": "í•´ê²°ë°©ì•ˆ ë„ì¶œ",
            "prompt_text": "ë¶„ì„ëœ ë¬¸ì œì— ëŒ€í•´ ì‹¤ìš©ì ì¸ í•´ê²°ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.",
            "stepOrder": 2
        },
        {
            "promptId": "validation_card", 
            "title": "ë‹µë³€ ê²€ì¦",
            "prompt_text": "ì œì‹œëœ í•´ê²°ë°©ì•ˆì˜ ì¥ë‹¨ì ì„ ë¶„ì„í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•˜ì„¸ìš”.",
            "stepOrder": 3
        }
    ]
    
    workflow = create_user_workflow(user_cards)
    """
    return create_dynamic_workflow_from_cards(user_prompt_cards)